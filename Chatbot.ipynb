{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52959fe-d560-4399-9ec6-f5c75577a897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging==23.2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install packaging==23.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801bec50-3863-4665-a4ff-47b38bfea2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\digvi\\anaconda3\\lib\\site-packages (0.2.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (0.2.37)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (0.1.108)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (4.12.2)\n",
      "Collecting langchain-core<0.3.0,>=0.2.35 (from langchain)\n",
      "  Downloading langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/51.8 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/51.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 51.8/51.8 kB 532.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (2.1)\n",
      "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "   ---------------------------------------- 0.0/397.0 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/397.0 kB 3.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 92.2/397.0 kB 1.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 92.2/397.0 kB 1.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 92.2/397.0 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------- ---------------------- 163.8/397.0 kB 817.0 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 163.8/397.0 kB 817.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  389.1/397.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 397.0/397.0 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "   ---------------------------------------- 0.0/296.9 kB ? eta -:--:--\n",
      "   --------------------------------- ----- 256.0/296.9 kB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 296.9/296.9 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.3/139.3 kB 8.1 MB/s eta 0:00:00\n",
      "Installing collected packages: orjson, langsmith, langchain-core, langchain-text-splitters\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.108\n",
      "    Uninstalling langsmith-0.1.108:\n",
      "      Successfully uninstalled langsmith-0.1.108\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.37\n",
      "    Uninstalling langchain-core-0.2.37:\n",
      "      Successfully uninstalled langchain-core-0.2.37\n",
      "Successfully installed langchain-core-0.2.41 langchain-text-splitters-0.2.4 langsmith-0.1.137 orjson-3.10.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8441bda8-5310-4062-a2dd-40bd9d82f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\n",
      "langchain 0.2.15 requires langchain-core<0.3.0,>=0.2.35, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-community 0.2.15 requires langchain-core<0.3.0,>=0.2.37, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-google-vertexai 1.0.10 requires langchain-core<0.3,>=0.2.33, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.13 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b4931c-dd8e-4b13-88f0-8ca807269aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass   #This module is used to securely prompt the user for a password or, in this case, an API key without echoing it to the terminal.\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  #Tracing is used to monitor and debug the behavior of chains and agents in LangChain, providing detailed logs of their execution.\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()  #enter their LangChain API key securely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c1c021-499b-4ded-9c1f-644ccfb52d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI  #provides an interface to OpenAI's chat models.\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d10ff11d-2431-42fc-93b2-fd4ce5dcf603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Bob! How are you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 12, 'total_tokens': 20, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e72a9091-c4bd-4c02-a2bf-27fb1c126ff3-0', usage_metadata={'input_tokens': 12, 'output_tokens': 8, 'total_tokens': 20, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Empty request\"}')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage  #class representing a message from a human user. This message can then be passed to the model to generate a response.\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27eb2448-3198-455a-9675-08c6343d2f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I do not have the ability to know your name as I am an AI assistant. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 12, 'total_tokens': 40, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9b256144-c8c7-4778-8d4f-ddf237002b23-0', usage_metadata={'input_tokens': 12, 'output_tokens': 28, 'total_tokens': 40, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])  # since we haven't stored conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127a117f-8d2f-4506-b07d-152662ef6226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bob.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 35, 'total_tokens': 40, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e1a69a0f-6e32-475e-8a79-daeeb69f7c9b-0', usage_metadata={'input_tokens': 35, 'output_tokens': 5, 'total_tokens': 40, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e709b4e-d6e2-4789-905d-05c4813d20ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\digvi\\anaconda3\\lib\\site-packages (0.2.15)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.15 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.15)\n",
      "Collecting langchain-core<0.3.0,>=0.2.37 (from langchain_community)\n",
      "  Using cached langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.15->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.15->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain_community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.37->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Using cached langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "Installing collected packages: langchain-core\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.13\n",
      "    Uninstalling langchain-core-0.3.13:\n",
      "      Successfully uninstalled langchain-core-0.3.13\n",
      "Successfully installed langchain-core-0.2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.2.4 requires langchain-core<0.4.0,>=0.3.13, but you have langchain-core 0.2.41 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b9d0721-b5e5-41ea-b170-f89112801bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,   #defines the interface for handling chat history.\n",
    "    InMemoryChatMessageHistory,   #An implementation of BaseChatMessageHistory that stores chat messages in memory.\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory  #A wrapper that allows a model (runnable) to maintain and utilize chat history across different interactions.\n",
    "\n",
    "store = {}   #dictionary that will store chat histories for different sessions\n",
    "\n",
    "\n",
    "# get_session_history(session_id: str) -> BaseChatMessageHistory: A function that retrieves the chat history for a given session. If the session does not exist in store, it creates a new InMemoryChatMessageHistory instance and adds it to the store.\n",
    "# This function ensures that each session has its own separate history, which is crucial for maintaining context in multi-turn conversations.\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)  #This allows the model to maintain and utilize chat history across different turns of the conversation, making it capable of handling ongoing dialogues with context retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8d7461f-57c1-432e-a212-fd4561d65662",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"session1\"}}  # use a dict to store session id for chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89fcf718-de7c-4cec-a5ee-852c511a042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Bob! How can I assist you today?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e957cdf-aec0-4bb9-a8e3-116a84c77ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content # holds the result after invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c857757-8c1c-4d3a-86f8-a484392aceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I do not have access to your personal information such as your name. If you would like to share your name with me, I would be happy to address you by it.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we change to a new session id and the model has no history in 'store' pertaining to that session id and therefore the outut.\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"example\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df10efb2-0743-4393-bfdb-52be1bdd3c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after we change to the previous session id we get the respone aptly.\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"session1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ccfc842-6dca-4854-846b-a4e12b1243c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  #This class helps create and manage prompts for chat models, allowing you to define a structured template for generating responses.\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a funny assistant. Answer all questions with humour.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model  # This constructs a chain where the ChatPromptTemplate is applied to the input messages, and the resulting prompt is passed to the model. The | operator combines the two into a single workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2984bf5-0ddd-4590-a8ee-da4da4e416f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Bob! Are you sure you're not a computer pretending to be a human named Bob? Nice try!\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm bob\")]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3807d48-7a2e-4664-b384-2ea92d035704",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce90e92d-fe71-4639-89b3-1a35533d1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c12038f1-5e4e-4b01-911a-98278485e461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Linear algebra is like a math superhero that swoops in to save the day when you have a bunch of equations to solve. It's all about vectors, matrices, and linear transformations, oh my! So grab your cape and get ready to tackle some mathematical mysteries!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is linear algebra\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f014db47-7b83-406a-87e7-7b23271e1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d72c8762-b3db-4f40-b36f-968171b33266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola, Bob! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm bob\")], \"language\": \"Spanish\"}\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60489a9b-c5e9-4601-ae3e-ae3613ead8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fcd260b-72c9-429e-9ce4-2b85aa088ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc11\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e73f5d-151b-4eba-bdd6-260b8000a615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola Todd! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46408529-a30b-44bd-8bdd-cb1318ad973b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tu nombre es Todd. ¿En qué más puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f51b9ff5-9902-4174-826c-38be12f46f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "663915a3-f823-479a-8c9e-54e7bfa948dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about users.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter  #A utility from Python’s 'operator' module used to extract values from dictionaries or sequences.\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbf807fc-bc1b-4782-bc6f-9fae53df358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"what\\'s 2 + 2?\"'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb81d61-0438-401d-be9f-c7d52cc31465",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72335316-38bf-4f42-a13a-e06393089b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about users. How can I assist you today?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60f77c99-7c9f-401a-b088-dd5a7a5f1223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You haven't asked a math problem yet. Feel free to ask any math question you have, and I'll be happy to help you with it.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff9bb2-03d2-4833-a313-ae11d84b836a",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "daf969ba-ff06-4252-adad-80633f6db295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\digvi\\AppData\\Local\\Temp\\ipykernel_18872\\2820266863.py\", line 2, in <module>\n",
      "    for r in with_message_history.stream(\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5525, in stream\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5525, in stream\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3407, in stream\n",
      "    arbitrary_types_allowed = True\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3394, in transform\n",
      "    steps__={key: coerce_to_runnable(r) for key, r in merged.items()}\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2197, in _transform_stream_with_config\n",
      "    raise\n",
      "          \n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3357, in _transform\n",
      "    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\")\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5561, in transform\n",
      "    thing: A Runnable-like object.\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4820, in transform\n",
      "    **kwargs: Optional[Any],\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2161, in _transform_stream_with_config\n",
      "    while True:\n",
      "                \n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5561, in transform\n",
      "    thing: A Runnable-like object.\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4820, in transform\n",
      "    **kwargs: Optional[Any],\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2197, in _transform_stream_with_config\n",
      "    raise\n",
      "          \n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4787, in _transform\n",
      "    **kwargs: Any,\n",
      "                 ^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    if run_manager is not None and accepts_run_manager(func):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\history.py\", line 531, in _enter_history\n",
      "    # If historic messages were prepended to the input messages, remove them to\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\history.py\", line 456, in _get_input_messages\n",
      "    elif len(output_val) == 1:\n",
      "                ^^^^^^^^^^^^^^\n",
      "KeyError: 'input'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\digvi\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    print(r.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb0eaf-30b1-4e87-b315-817d5dafb572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
